# English Problem Solver v3
# ê¸°ëŠ¥1. í…ìŠ¤íŠ¸ ì…ë ¥í•˜ë©´ gpt-4-turboê°€ ë‹µë³€

# ê¸°ëŠ¥2. ì´ë¯¸ì§€ ì—…ë¡œë“œí•˜ë©´ gpt-4-visionì´ ë‹µë³€
# - ê·¸ë˜í”„ ì´ë¯¸ì§€ ì—…ë¡œë“œ
# - ì§€ë¬¸ í…ìŠ¤íŠ¸ ë³µì‚¬ë¶™ì—¬ë„£ê¸°

# share streamlit ì—ì„œ ë°°í¬

import base64
from PIL import Image as Img
import time

import streamlit as st
import openai
from openai import OpenAI
# from dotenv import load_dotenv
# load_dotenv()
# openai.api_key = os.environ.get('OPENAI_API_KEY')

openai.api_key = st.secrets["OPENAI_API_KEY"]
client = OpenAI()

from langchain.chat_models import ChatOpenAI
from transformers import Pix2StructProcessor, Pix2StructForConditionalGeneration

st.header("ğŸ“„English Problem SolverğŸ“Š")

# ì‚¬ì´ë“œì— listì˜ ì„ íƒë°•ìŠ¤ë¥¼ ìƒì„±
select = st.sidebar.selectbox('ë©”ë‰´', ['ê·¸ë˜í”„ ì´ë¯¸ì§€ ë¶„ì„', 'í…ìŠ¤íŠ¸ ë¶„ì„'])

if select == 'ê·¸ë˜í”„ ì´ë¯¸ì§€ ë¶„ì„':

    # ê·¸ë˜í”„ ì´ë¯¸ì§€ ì—…ë¡œë“œ
    st.text("")
    st.text("")
    graph_image_file = st.file_uploader("ê·¸ë˜í”„ ì´ë¯¸ì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”", type=['png', 'jpg', 'jpeg'], key="graph_image")
    if graph_image_file is not None:
        st.image(graph_image_file, width=500)
    else:
        st.info('â˜ï¸ ê·¸ë˜í”„ ë¬¸ì œë¥¼ ì—…ë¡œë“œí•˜ë©´ ë¬¸ì œë¥¼ í’€ì–´ë“œë¦½ë‹ˆë‹¤.')


    # ì§€ë¬¸ í…ìŠ¤íŠ¸ ì—…ë¡œë“œ
    st.text("")
    st.text("")
    passage = st.text_input("ì§€ë¬¸ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”(ì…ë ¥ í›„ ì—”í„°)")


    # # ë¬¸ì œ ì „ì²´ ì´ë¯¸ì§€ ì…ë ¥
    # st.text("")
    # st.text("")
    # full_image_file = st.file_uploader("ì „ì²´ ë¬¸ì œ ì´ë¯¸ì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”", type=['png', 'jpg', 'jpeg'], key="full_image")

    # ë²„íŠ¼ ëˆ„ë¥´ë©´ gptì—ê²Œ ë‹µë³€ ë°›ê¸° ì‹œì‘
    if st.button('í’€ì–´ì¤˜!'):
        start = time.time()  # ì‹œì‘ ì‹œê°„ ì €ì¥

        # --------------------------deplotìœ¼ë¡œ ìˆ˜ì¹˜ ì¶”ì¶œí•˜ê¸°-------------------------

        processor = Pix2StructProcessor.from_pretrained('nuua/ko-deplot')
        model = Pix2StructForConditionalGeneration.from_pretrained('nuua/ko-deplot')
        
        image = Img.open(graph_image_file)
        inputs = processor(images=image, text="Generate underlying data table of the figure below:", return_tensors="pt")
        predictions = model.generate(**inputs, max_new_tokens=512)
        result = processor.decode(predictions[0], skip_special_tokens=True)
        # result = ""

        # st.success(result)

        # --------------------------gpt-4-visionìœ¼ë¡œ ë¬¸ì œ í’€ê¸°--------------------------

        # ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ìƒì„±
        messages=[{"role": "system", "content": """You must answer in Korean. You're a mathematician who calculates numbers and makes comparisons with rigor and precision.
                    For comparing numbers, compare based on the absolute value of the subtraction.
                    If about the largest or smallest numbers, compare the numbers across all groups.
                    """}]

        # ì²«ë²ˆì§¸ ì§ˆë¬¸ ìƒì„±
        question = f""" ê·¸ë˜í”„ ë¶„ì„ resultë¥¼ ì œê³µí•´ì¤„ê²Œ. 
        graph analysis : {result}. 
        Q. ê·¸ë˜í”„ì˜ ë‚´ìš©ê³¼ ê°€ì¥ ë§ì§€ ì•Šì„ í™•ë¥ ì´ ë†’ì€ ë¬¸ì¥ì€?
        {passage}. 
        """ 

        graph_image_file = graph_image_file.name

        # Function to encode the image
        def encode_image(image_path):
            with open(image_path, "rb") as image_file:
                return base64.b64encode(image_file.read()).decode('utf-8')
                
        # Getting the base64 string
        base64_image = encode_image(graph_image_file)

        question_dict = {
                "role": "user",
                "content": [
                    {"type": "text", "text": question},
                    {
                    "type": "image_url",
                    "image_url": {
                        "url": f"data:image/jpeg;base64,{base64_image}",
                    },
                    },
                ],
                }

        # ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ì— ì§ˆë¬¸ ì¶”ê°€
        messages.append(question_dict)

        # ë‹µë³€ ë°›ê¸°
        completion = client.chat.completions.create(
            model="gpt-4-vision-preview",
            messages = messages,
        )

        response = completion.choices[0].message.content

        st.info(response)

        st.write("ì¶”ë¡  ì‹œê°„ :", int(time.time() - start), "ì´ˆ")     # í˜„ì¬ì‹œê° - ì‹œì‘ì‹œê°„ = ì‹¤í–‰ ì‹œê°„


if select == 'í…ìŠ¤íŠ¸ ë¶„ì„':
    # ì‚¬ìš©ì ì§ˆë¬¸ ì…ë ¥
    question = st.text_area("ë¬¸ì œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”", height=10)

    # ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ ìƒì„±
    messages=[{"role": "system", "content": """
               You must answer in Korean. You're a mathematician who calculates numbers and makes comparisons with rigor and precision.
               Think in steps when making size comparisons between figures. 
               """}]

    question_dict = {
                "role": "user",
                "content": question ,  # ì²« ë²ˆì§¸ ì§ˆë¬¸
            }

    # ë©”ì‹œì§€ íˆìŠ¤í† ë¦¬ì— ì§ˆë¬¸ ì¶”ê°€
    messages.append(question_dict)

    # ë²„íŠ¼ ëˆ„ë¥´ë©´ ë‹µë³€ ë°›ê¸° ì‹œì‘
    if st.button('í’€ì–´ì¤˜!'):
    # st.write('Why hello there')

        # ë‹µë³€ ë°›ê¸°
        completion = client.chat.completions.create(
            model="gpt-4-0125-preview",          # "gpt-3.5-turbo-0125", "gpt-4-0125-preview"
            messages = messages,
        )

        response = completion.choices[0].message.content

        st.info(response)
